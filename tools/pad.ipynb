{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:02:55.483570Z",
     "start_time": "2024-07-19T07:02:55.456629Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pad_image(image, target_size, type='rgb'):\n",
    "    \"\"\"\n",
    "    :param image: input image\n",
    "    :param target_size: a tuple (num,num)\n",
    "    :return: new image\n",
    "    \"\"\"\n",
    "    iw, ih = image.size\n",
    "    w, h = target_size\n",
    "\n",
    "    scale = min(w / iw, h / ih)\n",
    "\n",
    "    nw = int(iw * scale + 0.5)\n",
    "    nh = int(ih * scale + 0.5)\n",
    "\n",
    "    image = image.resize((nw, nh), Image.BICUBIC)\n",
    "    if type == 'rgb':\n",
    "        new_image = Image.new('RGB', target_size, (0, 0, 0))\n",
    "    else:\n",
    "        new_image = Image.new('L', target_size, (0))\n",
    "    new_image.paste(image, ((w - nw) // 2, (h - nh) // 2))\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:03:36.425665Z",
     "start_time": "2024-07-19T07:03:36.232406Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the path to the folder containing the images\n",
    "folder_path = '../datasets/aim500/test/trimap'\n",
    "\n",
    "# Get a list of all the image file names in the folder\n",
    "image_files = [file for file in os.listdir(folder_path) if file.endswith('.png')]\n",
    "\n",
    "# Loop through each image file\n",
    "for file_name in image_files:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Open the image\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Apply the pad_image function to crop the image\n",
    "    cropped_image = pad_image(image, (512, 512))\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(folder_path, f\"{file_name}\")\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class Self_Attn(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.reduce_dim=nn.Sequential(\n",
    "            nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1),  # 保持通道数量不变\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 尺寸减半 (128x128 -> 64x64)\n",
    "            \n",
    "            nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1),  # 保持通道数量不变\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 尺寸再减半 (64x64 -> 32x32)\n",
    "        )\n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "    def forward(self,x,y):\n",
    "        x=self.reduce_dim(x)\n",
    "        y=self.reduce_dim(y)\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        \n",
    "        yproj_query  = self.query_conv(y).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        yproj_key =  self.key_conv(y).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "\n",
    "        proj_query=torch.add(proj_query,yproj_query)\n",
    "        \n",
    "        proj_key=torch.add(proj_key,yproj_key)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        \n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "        yproj_value = self.value_conv(y).view(m_batchsize,-1,width*height) # B X C X N\n",
    "        \n",
    "        proj_value=torch.add(proj_value,yproj_value)\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        out=self.value_conv(out)\n",
    "        \n",
    "        return out.view(out.size(0), out.size(1), -1)\n",
    "    \n",
    "    \n",
    "x=torch.randn(1,128,128,128)\n",
    "y=torch.randn(1,128,128,128)\n",
    "model=Self_Attn(in_dim=128)\n",
    "print(model(x,y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "class encoderfusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(encoderfusion, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1)  # Output: (1, 64, 256, 256)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)  # Output: (1, 128, 128, 128)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)  # Output: (1, 256, 64, 64)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.reduce = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)  # Output: (1, 256, 64, 64)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "    \n",
    "    def forward(self, feat,prompt):\n",
    "        x = F.relu(self.bn1(self.conv1(prompt)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        fusion=torch.cat((feat,x),1)\n",
    "        reduce=self.bn4(self.reduce(fusion))\n",
    "        return reduce\n",
    "\n",
    "\n",
    "x=torch.randn(1,256,64,64)\n",
    "y=torch.randn(1,1,512,512)\n",
    "model=encoderfusion()\n",
    "print(model(x,y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ../datasets/aim500/test/mask/o_1c321c56.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0a09b978.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0c33063a.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1a9abc07.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1b224771.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0b7228ec.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1ae3ae29.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_2b0e2eed.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1ea2b894.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0df5178f.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1b4c1dfc.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1edbc402.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0a0ae43d.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_1f836c45.jpg\n",
      "Processed ../datasets/aim500/test/mask/o_0bf712f6.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_images(folder_path):\n",
    "    # 获取文件夹中的所有文件\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # 读取图像\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is not None:\n",
    "            # 将像素值小于30的设置为0\n",
    "            image[image < 2] = 0\n",
    "            \n",
    "            # 保存处理后的图像\n",
    "            cv2.imwrite(file_path, image)\n",
    "            print(f'Processed {file_path}')\n",
    "        else:\n",
    "            print(f'Could not read {file_path}')\n",
    "\n",
    "folder_path = '../datasets/aim500/test/mask'  # 替换为你的文件夹路径\n",
    "process_images(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4420e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_mse(pred, target, trimap):\n",
    "    # 确保所有张量在相同的设备上\n",
    "    device = pred.device\n",
    "    target = target.to(device)\n",
    "    trimap = trimap.to(device)\n",
    "\n",
    "    # 计算误差映射\n",
    "    error_map = (pred - target) / 255.0\n",
    "\n",
    "    # 计算损失\n",
    "    valid_mask = (trimap == 128).float()\n",
    "    loss = torch.sum((error_map ** 2) * valid_mask) / (torch.sum(valid_mask) + 1e-8)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# 示例用法\n",
    "pred = torch.randn(1, 1, 512, 512).cuda()  # 示例预测张量\n",
    "target = torch.randn(1, 1, 512, 512).cuda()  # 示例目标张量\n",
    "trimap = torch.randint(0, 256, (1, 1, 512, 512)).cuda()  # 示例 trimap 张量，值在 [0, 255] 范围内\n",
    "\n",
    "mse_loss = compute_mse(pred, target, trimap)\n",
    "print(mse_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paintmatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
